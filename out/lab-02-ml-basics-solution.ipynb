{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 2: Machine Learning Basics - SOLUTIONS\n",
        "\n",
        "**Day 1 - Foundations**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score, confusion_matrix\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 1: Data Splitting - SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_data(X, y, test_size=0.2, random_state=42):\n",
        "    return train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
        "\n",
        "# Test\n",
        "X = np.random.randn(100, 2)\n",
        "y = (X[:, 0] + X[:, 1] > 0).astype(int)\n",
        "X_train, X_test, y_train, y_test = split_data(X, y)\n",
        "print(f\"Training set: {X_train.shape[0]} samples\")\n",
        "print(f\"Test set: {X_test.shape[0]} samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 2: Linear Regression from Scratch - SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SimpleLinearRegression:\n",
        "    def __init__(self):\n",
        "        self.slope = None\n",
        "        self.intercept = None\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        X = X.flatten()\n",
        "        x_mean = np.mean(X)\n",
        "        y_mean = np.mean(y)\n",
        "        \n",
        "        numerator = np.sum((X - x_mean) * (y - y_mean))\n",
        "        denominator = np.sum((X - x_mean) ** 2)\n",
        "        \n",
        "        self.slope = numerator / denominator\n",
        "        self.intercept = y_mean - self.slope * x_mean\n",
        "        return self\n",
        "    \n",
        "    def predict(self, X):\n",
        "        X = X.flatten()\n",
        "        return self.slope * X + self.intercept\n",
        "\n",
        "# Test\n",
        "X_reg = np.random.rand(100, 1) * 10\n",
        "y_reg = 2.5 * X_reg.flatten() + 5 + np.random.randn(100) * 2\n",
        "\n",
        "model = SimpleLinearRegression()\n",
        "model.fit(X_reg, y_reg)\n",
        "print(f\"Slope: {model.slope:.4f} (expected ~2.5)\")\n",
        "print(f\"Intercept: {model.intercept:.4f} (expected ~5.0)\")\n",
        "\n",
        "y_pred = model.predict(X_reg)\n",
        "plt.scatter(X_reg, y_reg, alpha=0.5, label='Data')\n",
        "plt.plot(X_reg, y_pred, 'r-', linewidth=2, label='Prediction')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('y')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 3: Sklearn Regression - SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_sklearn_regression(X_train, y_train, X_test):\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    return model, predictions\n",
        "\n",
        "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
        "    X_reg, y_reg, test_size=0.2, random_state=42\n",
        ")\n",
        "sk_model, sk_pred = train_sklearn_regression(X_train_reg, y_train_reg, X_test_reg)\n",
        "print(f\"Sklearn slope: {sk_model.coef_[0]:.4f}\")\n",
        "print(f\"Sklearn intercept: {sk_model.intercept_:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 4: Classification - SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_classifier(X_train, y_train):\n",
        "    model = LogisticRegression()\n",
        "    model.fit(X_train, y_train)\n",
        "    return model\n",
        "\n",
        "def get_predictions_and_probabilities(model, X_test):\n",
        "    predictions = model.predict(X_test)\n",
        "    probabilities = model.predict_proba(X_test)[:, 1]\n",
        "    return predictions, probabilities\n",
        "\n",
        "# Test\n",
        "X_clf, y_clf = make_classification(n_samples=200, n_features=2, n_redundant=0, \n",
        "                                   n_informative=2, n_clusters_per_class=1, random_state=42)\n",
        "X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(\n",
        "    X_clf, y_clf, test_size=0.2, random_state=42)\n",
        "\n",
        "clf = train_classifier(X_train_clf, y_train_clf)\n",
        "preds, probs = get_predictions_and_probabilities(clf, X_test_clf)\n",
        "print(f\"First 5 predictions: {preds[:5]}\")\n",
        "print(f\"First 5 probabilities: {probs[:5].round(3)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 5: Model Evaluation - SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_regression_metrics(y_true, y_pred):\n",
        "    mse = np.mean((y_true - y_pred) ** 2)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae = np.mean(np.abs(y_true - y_pred))\n",
        "    return {'MSE': mse, 'RMSE': rmse, 'MAE': mae}\n",
        "\n",
        "def calculate_classification_metrics(y_true, y_pred):\n",
        "    accuracy = np.mean(y_true == y_pred)\n",
        "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "    return {'accuracy': accuracy, 'confusion_matrix': conf_matrix}\n",
        "\n",
        "def plot_confusion_matrix(conf_matrix, classes=['Class 0', 'Class 1']):\n",
        "    plt.imshow(conf_matrix, cmap='Blues')\n",
        "    plt.colorbar()\n",
        "    plt.xticks([0, 1], classes)\n",
        "    plt.yticks([0, 1], classes)\n",
        "    for i in range(2):\n",
        "        for j in range(2):\n",
        "            plt.text(j, i, conf_matrix[i, j], ha='center', va='center', fontsize=14)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.title('Confusion Matrix')\n",
        "\n",
        "# Test\n",
        "y_pred_reg = sk_model.predict(X_test_reg)\n",
        "print(\"Regression Metrics:\", calculate_regression_metrics(y_test_reg, y_pred_reg))\n",
        "print(\"Classification Metrics:\", calculate_classification_metrics(y_test_clf, preds))\n",
        "\n",
        "plot_confusion_matrix(calculate_classification_metrics(y_test_clf, preds)['confusion_matrix'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 6: Overfitting Demonstration - SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def demonstrate_overfitting():\n",
        "    np.random.seed(42)\n",
        "    X = np.linspace(0, 4, 30).reshape(-1, 1)\n",
        "    y = np.sin(X.flatten() * 1.5) + np.random.randn(30) * 0.3\n",
        "    \n",
        "    plt.figure(figsize=(15, 4))\n",
        "    degrees = [1, 4, 15]\n",
        "    titles = ['Underfitting (degree=1)', 'Good Fit (degree=4)', 'Overfitting (degree=15)']\n",
        "    \n",
        "    for i, degree in enumerate(degrees):\n",
        "        plt.subplot(1, 3, i + 1)\n",
        "        \n",
        "        model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
        "        model.fit(X, y)\n",
        "        \n",
        "        X_smooth = np.linspace(0, 4, 100).reshape(-1, 1)\n",
        "        y_smooth = model.predict(X_smooth)\n",
        "        \n",
        "        plt.scatter(X, y, color='blue', alpha=0.5, label='Data')\n",
        "        plt.plot(X_smooth, y_smooth, 'r-', linewidth=2, label='Prediction')\n",
        "        plt.title(titles[i])\n",
        "        plt.xlabel('X')\n",
        "        plt.ylabel('y')\n",
        "        plt.legend()\n",
        "        plt.ylim(-2, 2)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "demonstrate_overfitting()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Checkpoint\n",
        "\n",
        "Lab 2 complete! **Next:** Lab 3 - Neural Networks"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
