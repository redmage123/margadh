{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 2: Machine Learning Basics\n",
        "\n",
        "**Day 1 - Foundations**\n",
        "\n",
        "| Duration | Difficulty | Prerequisites |\n",
        "|----------|------------|---------------|\n",
        "| 75 min | Beginner | Lab 1 |\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "- Understand supervised learning workflow\n",
        "- Implement linear regression from scratch\n",
        "- Use scikit-learn for classification\n",
        "- Evaluate model performance with metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score, confusion_matrix\n",
        "\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exercise 1: Understanding the ML Workflow\n",
        "\n",
        "The standard ML workflow:\n",
        "1. Collect/load data\n",
        "2. Explore and preprocess\n",
        "3. Split into train/test sets\n",
        "4. Train model\n",
        "5. Evaluate performance\n",
        "6. Iterate/improve\n",
        "\n",
        "**Your Task:** Implement the data splitting step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate synthetic data\n",
        "np.random.seed(42)\n",
        "X = np.random.randn(100, 2)  # 100 samples, 2 features\n",
        "y = (X[:, 0] + X[:, 1] > 0).astype(int)  # Binary classification\n",
        "\n",
        "print(f\"Features shape: {X.shape}\")\n",
        "print(f\"Labels shape: {y.shape}\")\n",
        "print(f\"Label distribution: {np.bincount(y)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_data(X, y, test_size=0.2, random_state=42):\n",
        "    \"\"\"\n",
        "    Split data into training and test sets.\n",
        "    \n",
        "    Args:\n",
        "        X: Feature matrix\n",
        "        y: Labels\n",
        "        test_size: Fraction for test set (0.2 = 20%)\n",
        "        random_state: Random seed for reproducibility\n",
        "    \n",
        "    Returns:\n",
        "        X_train, X_test, y_train, y_test\n",
        "    \"\"\"\n",
        "    # TODO: Use train_test_split from sklearn\n",
        "    # Hint: train_test_split(X, y, test_size=..., random_state=...)\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test Exercise 1\n",
        "result = split_data(X, y)\n",
        "if result is not None:\n",
        "    X_train, X_test, y_train, y_test = result\n",
        "    print(f\"Training set: {X_train.shape[0]} samples\")\n",
        "    print(f\"Test set: {X_test.shape[0]} samples\")\n",
        "else:\n",
        "    print(\"Implement split_data() function\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exercise 2: Linear Regression from Scratch\n",
        "\n",
        "Linear regression finds the best line: y = mx + b\n",
        "\n",
        "**Your Task:** Implement linear regression using the normal equation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate regression data\n",
        "np.random.seed(42)\n",
        "X_reg = np.random.rand(100, 1) * 10  # Feature: 0-10\n",
        "y_reg = 2.5 * X_reg.flatten() + 5 + np.random.randn(100) * 2  # y = 2.5x + 5 + noise\n",
        "\n",
        "plt.scatter(X_reg, y_reg, alpha=0.5)\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('y')\n",
        "plt.title('Linear Regression Data')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SimpleLinearRegression:\n",
        "    \"\"\"Linear regression from scratch.\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.slope = None  # m\n",
        "        self.intercept = None  # b\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        Fit the model using least squares.\n",
        "        \n",
        "        Formulas:\n",
        "        slope = sum((x - x_mean) * (y - y_mean)) / sum((x - x_mean)^2)\n",
        "        intercept = y_mean - slope * x_mean\n",
        "        \"\"\"\n",
        "        X = X.flatten()  # Make sure X is 1D\n",
        "        \n",
        "        # TODO: Calculate x_mean and y_mean\n",
        "        x_mean = None\n",
        "        y_mean = None\n",
        "        \n",
        "        # TODO: Calculate slope using the formula above\n",
        "        # numerator = sum((x - x_mean) * (y - y_mean))\n",
        "        # denominator = sum((x - x_mean)^2)\n",
        "        self.slope = None\n",
        "        \n",
        "        # TODO: Calculate intercept\n",
        "        self.intercept = None\n",
        "        \n",
        "        return self\n",
        "    \n",
        "    def predict(self, X):\n",
        "        \"\"\"Predict y = mx + b.\"\"\"\n",
        "        X = X.flatten()\n",
        "        # TODO: Return predictions using slope and intercept\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test Exercise 2\n",
        "model = SimpleLinearRegression()\n",
        "model.fit(X_reg, y_reg)\n",
        "\n",
        "if model.slope is not None:\n",
        "    print(f\"Slope: {model.slope:.4f} (expected ~2.5)\")\n",
        "    print(f\"Intercept: {model.intercept:.4f} (expected ~5.0)\")\n",
        "    \n",
        "    # Plot\n",
        "    y_pred = model.predict(X_reg)\n",
        "    plt.scatter(X_reg, y_reg, alpha=0.5, label='Data')\n",
        "    plt.plot(X_reg, y_pred, 'r-', linewidth=2, label='Prediction')\n",
        "    plt.xlabel('X')\n",
        "    plt.ylabel('y')\n",
        "    plt.legend()\n",
        "    plt.title('Linear Regression Fit')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Implement the fit() method\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exercise 3: Using Scikit-Learn\n",
        "\n",
        "Scikit-learn provides ready-to-use ML models.\n",
        "\n",
        "**Your Task:** Use sklearn's LinearRegression and compare."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_sklearn_regression(X_train, y_train, X_test):\n",
        "    \"\"\"\n",
        "    Train sklearn LinearRegression model.\n",
        "    \n",
        "    Returns:\n",
        "        model: Trained model\n",
        "        predictions: Predictions on X_test\n",
        "    \"\"\"\n",
        "    # TODO: Create LinearRegression model\n",
        "    model = None\n",
        "    \n",
        "    # TODO: Fit the model on training data\n",
        "    # model.fit(X_train, y_train)\n",
        "    \n",
        "    # TODO: Make predictions on test data\n",
        "    predictions = None\n",
        "    \n",
        "    return model, predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test Exercise 3\n",
        "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
        "    X_reg, y_reg, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "sk_model, sk_pred = train_sklearn_regression(X_train_reg, y_train_reg, X_test_reg)\n",
        "\n",
        "if sk_model is not None:\n",
        "    print(f\"Sklearn slope: {sk_model.coef_[0]:.4f}\")\n",
        "    print(f\"Sklearn intercept: {sk_model.intercept_:.4f}\")\n",
        "else:\n",
        "    print(\"Implement train_sklearn_regression()\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exercise 4: Classification with Logistic Regression\n",
        "\n",
        "Logistic regression predicts probabilities for classification.\n",
        "\n",
        "**Your Task:** Train a classifier and make predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate classification data\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "X_clf, y_clf = make_classification(\n",
        "    n_samples=200,\n",
        "    n_features=2,\n",
        "    n_redundant=0,\n",
        "    n_informative=2,\n",
        "    n_clusters_per_class=1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Visualize\n",
        "plt.scatter(X_clf[:, 0], X_clf[:, 1], c=y_clf, cmap='coolwarm', alpha=0.6)\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "plt.title('Classification Data')\n",
        "plt.colorbar(label='Class')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_classifier(X_train, y_train):\n",
        "    \"\"\"\n",
        "    Train a logistic regression classifier.\n",
        "    \n",
        "    Returns:\n",
        "        Trained LogisticRegression model\n",
        "    \"\"\"\n",
        "    # TODO: Create LogisticRegression model\n",
        "    # TODO: Fit on training data\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_predictions_and_probabilities(model, X_test):\n",
        "    \"\"\"\n",
        "    Get predictions and probability estimates.\n",
        "    \n",
        "    Returns:\n",
        "        predictions: Class predictions (0 or 1)\n",
        "        probabilities: Probability of class 1\n",
        "    \"\"\"\n",
        "    # TODO: Use model.predict() for class predictions\n",
        "    predictions = None\n",
        "    \n",
        "    # TODO: Use model.predict_proba() for probabilities\n",
        "    # Note: predict_proba returns [prob_class_0, prob_class_1]\n",
        "    probabilities = None\n",
        "    \n",
        "    return predictions, probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test Exercise 4\n",
        "X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(\n",
        "    X_clf, y_clf, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "clf = train_classifier(X_train_clf, y_train_clf)\n",
        "if clf is not None:\n",
        "    preds, probs = get_predictions_and_probabilities(clf, X_test_clf)\n",
        "    print(f\"First 5 predictions: {preds[:5]}\")\n",
        "    print(f\"First 5 probabilities: {probs[:5]}\")\n",
        "else:\n",
        "    print(\"Implement train_classifier()\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exercise 5: Model Evaluation\n",
        "\n",
        "Evaluating model performance is crucial.\n",
        "\n",
        "**Your Task:** Calculate various evaluation metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_regression_metrics(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculate regression metrics.\n",
        "    \n",
        "    Returns:\n",
        "        dict with MSE, RMSE, MAE\n",
        "    \"\"\"\n",
        "    # TODO: Calculate Mean Squared Error\n",
        "    # MSE = mean((y_true - y_pred)^2)\n",
        "    mse = None\n",
        "    \n",
        "    # TODO: Calculate Root Mean Squared Error\n",
        "    rmse = None\n",
        "    \n",
        "    # TODO: Calculate Mean Absolute Error\n",
        "    # MAE = mean(|y_true - y_pred|)\n",
        "    mae = None\n",
        "    \n",
        "    return {'MSE': mse, 'RMSE': rmse, 'MAE': mae}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_classification_metrics(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculate classification metrics.\n",
        "    \n",
        "    Returns:\n",
        "        dict with accuracy, confusion matrix\n",
        "    \"\"\"\n",
        "    # TODO: Calculate accuracy\n",
        "    # Accuracy = correct predictions / total predictions\n",
        "    accuracy = None\n",
        "    \n",
        "    # TODO: Calculate confusion matrix\n",
        "    # Use confusion_matrix from sklearn.metrics\n",
        "    conf_matrix = None\n",
        "    \n",
        "    return {'accuracy': accuracy, 'confusion_matrix': conf_matrix}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(conf_matrix, classes=['Class 0', 'Class 1']):\n",
        "    \"\"\"\n",
        "    Visualize confusion matrix.\n",
        "    \"\"\"\n",
        "    # TODO: Use plt.imshow() to visualize\n",
        "    # Add labels for each cell\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test Exercise 5\n",
        "if sk_model is not None:\n",
        "    y_pred_reg = sk_model.predict(X_test_reg)\n",
        "    reg_metrics = calculate_regression_metrics(y_test_reg, y_pred_reg)\n",
        "    print(\"Regression Metrics:\")\n",
        "    for name, value in reg_metrics.items():\n",
        "        if value is not None:\n",
        "            print(f\"  {name}: {value:.4f}\")\n",
        "\n",
        "if clf is not None and preds is not None:\n",
        "    clf_metrics = calculate_classification_metrics(y_test_clf, preds)\n",
        "    print(\"\\nClassification Metrics:\")\n",
        "    if clf_metrics['accuracy'] is not None:\n",
        "        print(f\"  Accuracy: {clf_metrics['accuracy']:.4f}\")\n",
        "    if clf_metrics['confusion_matrix'] is not None:\n",
        "        print(f\"  Confusion Matrix:\\n{clf_metrics['confusion_matrix']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exercise 6: Understanding Overfitting\n",
        "\n",
        "**Your Task:** Observe overfitting with polynomial regression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "def demonstrate_overfitting():\n",
        "    \"\"\"Show underfitting, good fit, and overfitting.\"\"\"\n",
        "    # Generate noisy sine wave data\n",
        "    np.random.seed(42)\n",
        "    X = np.linspace(0, 4, 30).reshape(-1, 1)\n",
        "    y = np.sin(X.flatten() * 1.5) + np.random.randn(30) * 0.3\n",
        "    \n",
        "    plt.figure(figsize=(15, 4))\n",
        "    degrees = [1, 4, 15]  # Underfit, Good fit, Overfit\n",
        "    titles = ['Underfitting (degree=1)', 'Good Fit (degree=4)', 'Overfitting (degree=15)']\n",
        "    \n",
        "    for i, degree in enumerate(degrees):\n",
        "        plt.subplot(1, 3, i + 1)\n",
        "        \n",
        "        # TODO: Create polynomial model with given degree\n",
        "        # Hint: make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
        "        model = None\n",
        "        \n",
        "        # TODO: Fit model and predict on dense X values for smooth line\n",
        "        # X_smooth = np.linspace(0, 4, 100).reshape(-1, 1)\n",
        "        \n",
        "        plt.scatter(X, y, color='blue', alpha=0.5, label='Data')\n",
        "        # TODO: Plot the prediction line\n",
        "        \n",
        "        plt.title(titles[i])\n",
        "        plt.xlabel('X')\n",
        "        plt.ylabel('y')\n",
        "        plt.legend()\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test Exercise 6\n",
        "demonstrate_overfitting()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Checkpoint\n",
        "\n",
        "Congratulations! You've completed Lab 2.\n",
        "\n",
        "### Key Takeaways:\n",
        "- Always split data into train/test sets\n",
        "- Linear regression finds the best line through data\n",
        "- Logistic regression is for classification\n",
        "- Evaluation metrics help assess model quality\n",
        "- Overfitting = memorizing, not learning\n",
        "\n",
        "**Next:** Lab 3 - Neural Networks"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
