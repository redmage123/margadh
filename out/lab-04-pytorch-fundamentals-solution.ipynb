{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 4: PyTorch Fundamentals - SOLUTIONS\n",
        "\n",
        "**Day 2 - Deep Learning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 1: Tensor Basics - SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_tensors():\n",
        "    tensor_from_list = torch.tensor([1, 2, 3, 4])\n",
        "    zeros = torch.zeros(3, 3)\n",
        "    ones = torch.ones(3, 3)\n",
        "    random_tensor = torch.rand(3, 3)\n",
        "    from_numpy = torch.from_numpy(np.array([[1, 2], [3, 4]]))\n",
        "    return tensor_from_list, zeros, ones, random_tensor, from_numpy\n",
        "\n",
        "def tensor_operations():\n",
        "    a = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32)\n",
        "    b = torch.tensor([[5, 6], [7, 8]], dtype=torch.float32)\n",
        "    return a + b, a * b, a @ b, torch.sum(a), torch.mean(a)\n",
        "\n",
        "# Test\n",
        "for i, t in enumerate(create_tensors()):\n",
        "    print(f\"Tensor {i+1}: shape={t.shape}\")\n",
        "print(\"\\nOperations:\", tensor_operations())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 2: Automatic Differentiation - SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_gradients():\n",
        "    x = torch.tensor([2.0], requires_grad=True)\n",
        "    y = x**2 + 3*x + 1\n",
        "    y.backward()\n",
        "    return x.grad.item()\n",
        "\n",
        "def chain_rule_example():\n",
        "    x = torch.tensor([3.0], requires_grad=True)\n",
        "    g = 2 * x\n",
        "    y = g ** 2\n",
        "    y.backward()\n",
        "    return x.grad.item()\n",
        "\n",
        "print(f\"Gradient of x^2 + 3x + 1 at x=2: {compute_gradients()} (expected: 7)\")\n",
        "print(f\"Gradient of (2x)^2 at x=3: {chain_rule_example()} (expected: 24)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 3: Neural Networks - SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layer1 = nn.Linear(2, 4)\n",
        "        self.layer2 = nn.Linear(4, 1)\n",
        "        self.activation = nn.ReLU()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.activation(self.layer1(x))\n",
        "        return self.layer2(x)\n",
        "\n",
        "class FlexibleNet(nn.Module):\n",
        "    def __init__(self, layer_sizes):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "        for i in range(len(layer_sizes) - 1):\n",
        "            self.layers.append(nn.Linear(layer_sizes[i], layer_sizes[i+1]))\n",
        "    \n",
        "    def forward(self, x):\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            x = layer(x)\n",
        "            if i < len(self.layers) - 1:\n",
        "                x = torch.relu(x)\n",
        "        return x\n",
        "\n",
        "# Test\n",
        "simple_net = SimpleNet()\n",
        "print(simple_net)\n",
        "print(f\"Parameters: {sum(p.numel() for p in simple_net.parameters())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 4: Training Loop - SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_xor = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
        "y_xor = torch.tensor([[0], [1], [1], [0]], dtype=torch.float32)\n",
        "\n",
        "class XORNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layer1 = nn.Linear(2, 4)\n",
        "        self.layer2 = nn.Linear(4, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.layer1(x))\n",
        "        x = self.sigmoid(self.layer2(x))\n",
        "        return x\n",
        "\n",
        "def train_xor_network(model, X, y, epochs=1000, lr=0.1):\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    losses = []\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        predictions = model(X)\n",
        "        loss = criterion(predictions, y)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        losses.append(loss.item())\n",
        "    \n",
        "    return losses\n",
        "\n",
        "# Train\n",
        "xor_model = XORNet()\n",
        "losses = train_xor_network(xor_model, X_xor, y_xor, epochs=2000, lr=0.5)\n",
        "\n",
        "print(\"After training:\")\n",
        "with torch.no_grad():\n",
        "    for x, actual in zip(X_xor, y_xor):\n",
        "        pred = xor_model(x.unsqueeze(0))\n",
        "        print(f\"  {x.tolist()} -> {pred.item():.4f} (expected {actual.item()})\")\n",
        "\n",
        "plt.plot(losses)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('XOR Training')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 5: nn.Sequential - SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_sequential_network():\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(10, 64),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(64, 32),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(32, 1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "seq_model = create_sequential_network()\n",
        "print(seq_model)\n",
        "print(f\"Parameters: {sum(p.numel() for p in seq_model.parameters())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 6: Complete Pipeline - SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_moons\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X, y = make_moons(n_samples=500, noise=0.2, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_t = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
        "X_test_t = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_t = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)\n",
        "\n",
        "def train_classifier(X_train, y_train, X_test, y_test, epochs=200):\n",
        "    model = nn.Sequential(\n",
        "        nn.Linear(2, 16),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(16, 8),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(8, 1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "    \n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "    \n",
        "    train_losses = []\n",
        "    test_accuracies = []\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        predictions = model(X_train)\n",
        "        loss = criterion(predictions, y_train)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        train_losses.append(loss.item())\n",
        "        \n",
        "        if epoch % 10 == 0:\n",
        "            with torch.no_grad():\n",
        "                test_pred = (model(X_test) > 0.5).float()\n",
        "                acc = (test_pred == y_test).float().mean().item()\n",
        "                test_accuracies.append(acc)\n",
        "    \n",
        "    return model, train_losses, test_accuracies\n",
        "\n",
        "model, losses, accs = train_classifier(X_train_t, y_train_t, X_test_t, y_test_t, epochs=500)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "axes[0].plot(losses)\n",
        "axes[0].set_title('Training Loss')\n",
        "axes[1].plot(range(0, 500, 10), accs)\n",
        "axes[1].set_title('Test Accuracy')\n",
        "plt.show()\n",
        "\n",
        "print(f\"Final accuracy: {accs[-1]:.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Checkpoint\n",
        "\n",
        "Lab 4 complete! **Next:** Lab 5 - NLP Basics"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
