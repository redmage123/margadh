{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 6: LLM APIs\n",
        "\n",
        "**Day 3 - From Deep Learning to LLMs**\n",
        "\n",
        "| Duration | Difficulty | Prerequisites |\n",
        "|----------|------------|---------------|\n",
        "| 60 min | Beginner | Labs 1-5 |\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "- Use the OpenAI API for text generation\n",
        "- Understand prompt engineering basics\n",
        "- Build a simple chatbot\n",
        "- Learn about API parameters (temperature, tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from openai import OpenAI\n",
        "\n",
        "# Set your API key\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"your-api-key-here\"\n",
        "client = OpenAI()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exercise 1: Basic API Call\n",
        "\n",
        "The Chat Completions API is the primary interface for LLMs.\n",
        "\n",
        "**Your Task:** Make your first API call."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def simple_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
        "    \"\"\"\n",
        "    Make a simple API call to get a completion.\n",
        "    \n",
        "    Args:\n",
        "        prompt: The user's message\n",
        "        model: Which model to use\n",
        "    \n",
        "    Returns:\n",
        "        The assistant's response text\n",
        "    \"\"\"\n",
        "    # TODO: Call client.chat.completions.create()\n",
        "    # with messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    \n",
        "    # TODO: Extract and return the response text\n",
        "    # response.choices[0].message.content\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test Exercise 1\n",
        "response = simple_completion(\"What is machine learning in one sentence?\")\n",
        "print(f\"Response: {response}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exercise 2: System Prompts\n",
        "\n",
        "System prompts set the behavior and persona of the assistant.\n",
        "\n",
        "**Your Task:** Use system prompts to control responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def completion_with_system(prompt, system_prompt, model=\"gpt-3.5-turbo\"):\n",
        "    \"\"\"\n",
        "    Make an API call with a system prompt.\n",
        "    \n",
        "    The messages should be:\n",
        "    [{\"role\": \"system\", \"content\": system_prompt},\n",
        "     {\"role\": \"user\", \"content\": prompt}]\n",
        "    \"\"\"\n",
        "    # TODO: Implement API call with system message\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test Exercise 2 - Different personas\n",
        "prompts_and_personas = [\n",
        "    (\"What is Python?\", \"You are a helpful teacher who explains concepts simply.\"),\n",
        "    (\"What is Python?\", \"You are a technical expert who gives precise definitions.\"),\n",
        "    (\"What is Python?\", \"You are a comedian who makes everything funny.\"),\n",
        "]\n",
        "\n",
        "for prompt, persona in prompts_and_personas:\n",
        "    response = completion_with_system(prompt, persona)\n",
        "    print(f\"Persona: {persona[:40]}...\")\n",
        "    print(f\"Response: {response}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exercise 3: Temperature and Tokens\n",
        "\n",
        "Temperature controls randomness. Max tokens limits response length.\n",
        "\n",
        "**Your Task:** Experiment with these parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def controlled_completion(prompt, temperature=0.7, max_tokens=100, model=\"gpt-3.5-turbo\"):\n",
        "    \"\"\"\n",
        "    Make an API call with temperature and token controls.\n",
        "    \n",
        "    Temperature:\n",
        "    - 0.0: Deterministic, focused\n",
        "    - 0.7: Balanced (default)\n",
        "    - 1.5-2.0: Creative, more random\n",
        "    \n",
        "    Max tokens:\n",
        "    - Limits the length of the response\n",
        "    - 1 token ~ 4 characters\n",
        "    \"\"\"\n",
        "    # TODO: Add temperature and max_tokens parameters to API call\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test Exercise 3 - Temperature comparison\n",
        "prompt = \"Write a creative product name for a new smartphone.\"\n",
        "\n",
        "print(\"Low temperature (0.0) - Consistent:\")\n",
        "for i in range(3):\n",
        "    response = controlled_completion(prompt, temperature=0.0, max_tokens=20)\n",
        "    print(f\"  {i+1}: {response}\")\n",
        "\n",
        "print(\"\\nHigh temperature (1.5) - Variable:\")\n",
        "for i in range(3):\n",
        "    response = controlled_completion(prompt, temperature=1.5, max_tokens=20)\n",
        "    print(f\"  {i+1}: {response}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exercise 4: Prompt Engineering\n",
        "\n",
        "Good prompts lead to better responses.\n",
        "\n",
        "**Your Task:** Practice common prompt techniques."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def zero_shot(task):\n",
        "    \"\"\"\n",
        "    Zero-shot: Ask the model directly without examples.\n",
        "    \"\"\"\n",
        "    # TODO: Call the API with just the task\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def few_shot(task, examples):\n",
        "    \"\"\"\n",
        "    Few-shot: Provide examples before the task.\n",
        "    \n",
        "    Args:\n",
        "        task: The task to perform\n",
        "        examples: List of (input, output) tuples\n",
        "    \n",
        "    Example prompt format:\n",
        "    Input: example1_input\n",
        "    Output: example1_output\n",
        "    \n",
        "    Input: example2_input\n",
        "    Output: example2_output\n",
        "    \n",
        "    Input: task\n",
        "    Output:\n",
        "    \"\"\"\n",
        "    # TODO: Build prompt with examples and call API\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def chain_of_thought(problem):\n",
        "    \"\"\"\n",
        "    Chain of Thought: Ask model to reason step by step.\n",
        "    \n",
        "    Append \"Let's think step by step:\" to the prompt.\n",
        "    \"\"\"\n",
        "    # TODO: Add chain-of-thought instruction\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test Exercise 4\n",
        "\n",
        "# Zero-shot\n",
        "print(\"Zero-shot classification:\")\n",
        "response = zero_shot(\"Classify this review as positive or negative: 'This movie was terrible!'\")\n",
        "print(f\"  {response}\\n\")\n",
        "\n",
        "# Few-shot\n",
        "print(\"Few-shot sentiment:\")\n",
        "examples = [\n",
        "    (\"I love this product!\", \"positive\"),\n",
        "    (\"Worst purchase ever.\", \"negative\"),\n",
        "    (\"It's okay, nothing special.\", \"neutral\")\n",
        "]\n",
        "response = few_shot(\"The service was excellent!\", examples)\n",
        "print(f\"  {response}\\n\")\n",
        "\n",
        "# Chain of thought\n",
        "print(\"Chain of thought:\")\n",
        "response = chain_of_thought(\"If I have 3 apples and give away 2, then buy 5 more, how many do I have?\")\n",
        "print(f\"  {response}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exercise 5: Conversation History\n",
        "\n",
        "Maintaining history enables multi-turn conversations.\n",
        "\n",
        "**Your Task:** Build a simple chatbot with memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SimpleChatbot:\n",
        "    \"\"\"\n",
        "    A chatbot that maintains conversation history.\n",
        "    \"\"\"\n",
        "    def __init__(self, system_prompt=\"You are a helpful assistant.\"):\n",
        "        # TODO: Initialize messages list with system prompt\n",
        "        # self.messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
        "        pass\n",
        "    \n",
        "    def chat(self, user_message):\n",
        "        \"\"\"\n",
        "        Send a message and get a response.\n",
        "        \n",
        "        1. Add user message to history\n",
        "        2. Call API with full history\n",
        "        3. Add assistant response to history\n",
        "        4. Return response\n",
        "        \"\"\"\n",
        "        # TODO: Implement chat method\n",
        "        pass\n",
        "    \n",
        "    def get_history(self):\n",
        "        \"\"\"Return conversation history.\"\"\"\n",
        "        return self.messages\n",
        "    \n",
        "    def clear_history(self):\n",
        "        \"\"\"Clear conversation history (keep system prompt).\"\"\"\n",
        "        # TODO: Keep only the system message\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test Exercise 5\n",
        "bot = SimpleChatbot(\"You are a friendly Python tutor.\")\n",
        "\n",
        "# Multi-turn conversation\n",
        "messages = [\n",
        "    \"What is a list in Python?\",\n",
        "    \"How do I add an item to it?\",\n",
        "    \"What about removing items?\"\n",
        "]\n",
        "\n",
        "for msg in messages:\n",
        "    print(f\"User: {msg}\")\n",
        "    response = bot.chat(msg)\n",
        "    print(f\"Assistant: {response}\\n\")\n",
        "\n",
        "print(f\"History length: {len(bot.get_history())} messages\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exercise 6: Structured Output\n",
        "\n",
        "Getting structured data (JSON) from LLMs.\n",
        "\n",
        "**Your Task:** Extract structured information from text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_structured_data(text, schema_description):\n",
        "    \"\"\"\n",
        "    Extract structured data from text.\n",
        "    \n",
        "    Args:\n",
        "        text: The text to extract from\n",
        "        schema_description: Description of expected JSON structure\n",
        "    \n",
        "    Returns:\n",
        "        Parsed JSON data\n",
        "    \"\"\"\n",
        "    system = f\"\"\"You are a data extraction assistant.\n",
        "Extract information from the text and return ONLY valid JSON.\n",
        "Expected format: {schema_description}\n",
        "Return ONLY the JSON, no other text.\"\"\"\n",
        "    \n",
        "    # TODO: Call API and parse JSON response\n",
        "    # Use json.loads() to parse the response\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def summarize_with_structure(text):\n",
        "    \"\"\"\n",
        "    Summarize text with structured output.\n",
        "    \n",
        "    Output format:\n",
        "    {\n",
        "        \"title\": \"...\",\n",
        "        \"summary\": \"...\",\n",
        "        \"key_points\": [\"...\", \"...\"],\n",
        "        \"sentiment\": \"positive/negative/neutral\"\n",
        "    }\n",
        "    \"\"\"\n",
        "    schema = '''{\n",
        "        \"title\": \"brief title\",\n",
        "        \"summary\": \"2-3 sentence summary\",\n",
        "        \"key_points\": [\"point1\", \"point2\"],\n",
        "        \"sentiment\": \"positive/negative/neutral\"\n",
        "    }'''\n",
        "    \n",
        "    # TODO: Use extract_structured_data\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test Exercise 6\n",
        "sample_text = \"\"\"\n",
        "The new Python 3.12 release brings significant performance improvements, \n",
        "with some benchmarks showing up to 5% faster execution. The release also \n",
        "includes better error messages that help developers debug issues more quickly.\n",
        "Additionally, the new f-string syntax improvements make string formatting \n",
        "more intuitive. Developers are excited about these changes.\n",
        "\"\"\"\n",
        "\n",
        "result = summarize_with_structure(sample_text)\n",
        "if result:\n",
        "    print(json.dumps(result, indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Bonus: Function Calling (Optional)\n",
        "\n",
        "LLMs can call functions you define."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_weather(location):\n",
        "    \"\"\"Simulated weather function.\"\"\"\n",
        "    # In production, this would call a real weather API\n",
        "    return {\"location\": location, \"temperature\": 72, \"condition\": \"sunny\"}\n",
        "\n",
        "def function_calling_example(user_message):\n",
        "    \"\"\"\n",
        "    Example of function calling with OpenAI.\n",
        "    \n",
        "    Note: This requires understanding of the function calling API.\n",
        "    See OpenAI documentation for details.\n",
        "    \"\"\"\n",
        "    tools = [\n",
        "        {\n",
        "            \"type\": \"function\",\n",
        "            \"function\": {\n",
        "                \"name\": \"get_weather\",\n",
        "                \"description\": \"Get current weather for a location\",\n",
        "                \"parameters\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"location\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"description\": \"City name\"\n",
        "                        }\n",
        "                    },\n",
        "                    \"required\": [\"location\"]\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    ]\n",
        "    \n",
        "    # First call - model decides if it needs to call a function\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\": \"user\", \"content\": user_message}],\n",
        "        tools=tools\n",
        "    )\n",
        "    \n",
        "    # Check if model wants to call a function\n",
        "    if response.choices[0].message.tool_calls:\n",
        "        tool_call = response.choices[0].message.tool_calls[0]\n",
        "        args = json.loads(tool_call.function.arguments)\n",
        "        \n",
        "        # Execute the function\n",
        "        result = get_weather(args[\"location\"])\n",
        "        \n",
        "        # Send result back to model\n",
        "        messages = [\n",
        "            {\"role\": \"user\", \"content\": user_message},\n",
        "            response.choices[0].message,\n",
        "            {\"role\": \"tool\", \"tool_call_id\": tool_call.id, \"content\": json.dumps(result)}\n",
        "        ]\n",
        "        \n",
        "        final = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=messages\n",
        "        )\n",
        "        return final.choices[0].message.content\n",
        "    \n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test function calling (optional - requires API key)\n",
        "# response = function_calling_example(\"What's the weather in New York?\")\n",
        "# print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Checkpoint\n",
        "\n",
        "Congratulations! You've completed Lab 6 and the entire course!\n",
        "\n",
        "### Key Takeaways:\n",
        "- OpenAI API uses chat completions format\n",
        "- System prompts control assistant behavior\n",
        "- Temperature affects randomness\n",
        "- Prompt engineering improves results\n",
        "- Conversation history enables multi-turn chat\n",
        "- Structured output enables data extraction\n",
        "\n",
        "### Course Complete!\n",
        "\n",
        "You've learned:\n",
        "- **Day 1:** Python for Data Science, ML Fundamentals\n",
        "- **Day 2:** Neural Networks, PyTorch\n",
        "- **Day 3:** NLP, Transformers, LLM APIs\n",
        "\n",
        "**Part 2 Preview:** RAG, Fine-tuning, Advanced Agents"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
