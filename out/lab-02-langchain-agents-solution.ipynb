{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: Building LangChain Agents - SOLUTIONS\n",
    "\n",
    "**Module 2 - AI Agents and Framework Implementation**\n",
    "\n",
    "| Duration | Difficulty | Framework | Exercises |\n",
    "|----------|------------|-----------|----------|\n",
    "| 90 min | Intermediate | LangChain | 4 |\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Build custom tools for LangChain agents\n",
    "- Implement a ReAct agent from scratch\n",
    "- Create multi-tool agents\n",
    "- Add custom callbacks for monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "# !pip install langchain langchain-openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import tool, create_react_agent, AgentExecutor\n",
    "from langchain.tools import Tool, StructuredTool\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional\n",
    "\n",
    "# Set your API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-api-key-here\"  # Replace with your key\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 1: Create a Calculator Tool - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"\n",
    "    Evaluate a mathematical expression.\n",
    "    Use this tool for any math calculations.\n",
    "    Input should be a valid mathematical expression like '2 + 2' or '(5 * 3) - 10'.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Only allow safe mathematical operations\n",
    "        allowed_chars = set('0123456789+-*/.() ')\n",
    "        if not all(c in allowed_chars for c in expression):\n",
    "            return \"Error: Invalid characters in expression\"\n",
    "        \n",
    "        # Evaluate the expression\n",
    "        result = eval(expression)\n",
    "        return f\"Result: {result}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the calculator tool\n",
    "print(calculator.invoke(\"2 + 2\"))\n",
    "print(calculator.invoke(\"(10 * 5) / 2\"))\n",
    "print(calculator.invoke(\"2 ** 8\"))  # Note: ** might not work with our filter\n",
    "print(calculator.invoke(\"100 - 37\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 2: Create a Weather Tool with Structured Input - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input schema\n",
    "class WeatherInput(BaseModel):\n",
    "    \"\"\"Input schema for weather lookup.\"\"\"\n",
    "    location: str = Field(description=\"The city name to get weather for\")\n",
    "    units: Optional[str] = Field(default=\"celsius\", description=\"Temperature units: celsius or fahrenheit\")\n",
    "\n",
    "\n",
    "def get_weather(location: str, units: str = \"celsius\") -> str:\n",
    "    \"\"\"\n",
    "    Get the current weather for a location.\n",
    "    This is a mock implementation - in production, call a real weather API.\n",
    "    \"\"\"\n",
    "    # Mock weather data\n",
    "    mock_weather = {\n",
    "        \"london\": {\"temp_c\": 15, \"condition\": \"Cloudy\"},\n",
    "        \"new york\": {\"temp_c\": 22, \"condition\": \"Sunny\"},\n",
    "        \"tokyo\": {\"temp_c\": 28, \"condition\": \"Humid\"},\n",
    "        \"paris\": {\"temp_c\": 18, \"condition\": \"Partly Cloudy\"},\n",
    "        \"sydney\": {\"temp_c\": 25, \"condition\": \"Clear\"},\n",
    "    }\n",
    "    \n",
    "    # Normalize location name\n",
    "    location_lower = location.lower().strip()\n",
    "    \n",
    "    if location_lower not in mock_weather:\n",
    "        return f\"Weather data not available for {location}\"\n",
    "    \n",
    "    weather = mock_weather[location_lower]\n",
    "    temp = weather[\"temp_c\"]\n",
    "    \n",
    "    # Convert to Fahrenheit if requested\n",
    "    if units.lower() == \"fahrenheit\":\n",
    "        temp = (temp * 9/5) + 32\n",
    "        unit_symbol = \"°F\"\n",
    "    else:\n",
    "        unit_symbol = \"°C\"\n",
    "    \n",
    "    return f\"Weather in {location.title()}: {temp}{unit_symbol}, {weather['condition']}\"\n",
    "\n",
    "\n",
    "# Create the structured tool\n",
    "weather_tool = StructuredTool.from_function(\n",
    "    func=get_weather,\n",
    "    name=\"weather\",\n",
    "    description=\"Get current weather for a city. Provide location and optionally units (celsius/fahrenheit).\",\n",
    "    args_schema=WeatherInput\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the weather tool\n",
    "print(weather_tool.invoke({\"location\": \"London\"}))\n",
    "print(weather_tool.invoke({\"location\": \"Tokyo\", \"units\": \"fahrenheit\"}))\n",
    "print(weather_tool.invoke({\"location\": \"Paris\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 3: Build a Multi-Tool ReAct Agent - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReAct prompt template\n",
    "REACT_PROMPT = \"\"\"Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "Thought: {agent_scratchpad}\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(REACT_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the agent with tools\n",
    "tools = [calculator, weather_tool]\n",
    "\n",
    "# Create the ReAct agent\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "\n",
    "# Create the agent executor\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    "    max_iterations=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the agent with various queries\n",
    "queries = [\n",
    "    \"What is 25 * 4 + 100?\",\n",
    "    \"What's the weather like in London?\",\n",
    "    \"If it's 15 degrees in London and 28 degrees in Tokyo, what's the temperature difference?\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Query: {query}\")\n",
    "    print(\"-\" * 60)\n",
    "    result = agent_executor.invoke({\"input\": query})\n",
    "    print(f\"\\nFinal Answer: {result['output']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 4: Implement Custom Callbacks - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentMonitorCallback(BaseCallbackHandler):\n",
    "    \"\"\"Custom callback handler for monitoring agent execution.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.steps = []\n",
    "        self.total_tokens = 0\n",
    "        self.llm_calls = 0\n",
    "    \n",
    "    def on_llm_start(self, serialized, prompts, **kwargs):\n",
    "        \"\"\"Called when LLM starts processing.\"\"\"\n",
    "        self.llm_calls += 1\n",
    "        print(f\"\\n[CALLBACK] LLM Call #{self.llm_calls} starting...\")\n",
    "    \n",
    "    def on_llm_end(self, response, **kwargs):\n",
    "        \"\"\"Called when LLM finishes.\"\"\"\n",
    "        # Track token usage if available\n",
    "        if hasattr(response, 'llm_output') and response.llm_output:\n",
    "            token_usage = response.llm_output.get('token_usage', {})\n",
    "            tokens = token_usage.get('total_tokens', 0)\n",
    "            self.total_tokens += tokens\n",
    "            print(f\"[CALLBACK] LLM Call complete. Tokens used: {tokens}\")\n",
    "    \n",
    "    def on_tool_start(self, serialized, input_str, **kwargs):\n",
    "        \"\"\"Called when a tool starts executing.\"\"\"\n",
    "        tool_name = serialized.get(\"name\", \"unknown\")\n",
    "        print(f\"[CALLBACK] Tool '{tool_name}' starting with input: {input_str}\")\n",
    "    \n",
    "    def on_tool_end(self, output, **kwargs):\n",
    "        \"\"\"Called when a tool finishes.\"\"\"\n",
    "        print(f\"[CALLBACK] Tool finished with output: {output}\")\n",
    "    \n",
    "    def on_agent_action(self, action, **kwargs):\n",
    "        \"\"\"Called when agent decides on an action.\"\"\"\n",
    "        self.steps.append({\n",
    "            \"type\": \"action\",\n",
    "            \"tool\": action.tool,\n",
    "            \"input\": action.tool_input\n",
    "        })\n",
    "        print(f\"[CALLBACK] Agent action: {action.tool} with input: {action.tool_input}\")\n",
    "    \n",
    "    def on_agent_finish(self, finish, **kwargs):\n",
    "        \"\"\"Called when agent completes.\"\"\"\n",
    "        self.steps.append({\n",
    "            \"type\": \"finish\",\n",
    "            \"output\": finish.return_values.get('output', '')\n",
    "        })\n",
    "        print(f\"[CALLBACK] Agent finished!\")\n",
    "    \n",
    "    def get_summary(self):\n",
    "        \"\"\"Return execution summary.\"\"\"\n",
    "        return {\n",
    "            \"total_steps\": len(self.steps),\n",
    "            \"llm_calls\": self.llm_calls,\n",
    "            \"tokens_used\": self.total_tokens,\n",
    "            \"steps\": self.steps\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with callbacks\n",
    "callback = AgentMonitorCallback()\n",
    "\n",
    "# Recreate executor with callbacks\n",
    "agent_executor_with_callbacks = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=False,  # Set to False since callbacks provide our logging\n",
    "    callbacks=[callback],\n",
    "    handle_parsing_errors=True\n",
    ")\n",
    "\n",
    "# Run a query\n",
    "print(\"Running query with callback monitoring...\\n\")\n",
    "result = agent_executor_with_callbacks.invoke({\n",
    "    \"input\": \"What is 15 * 8 and what's the weather in Paris?\"\n",
    "})\n",
    "\n",
    "# Get summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXECUTION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "summary = callback.get_summary()\n",
    "print(f\"Total steps: {summary['total_steps']}\")\n",
    "print(f\"LLM calls: {summary['llm_calls']}\")\n",
    "print(f\"Tokens used: {summary['tokens_used']}\")\n",
    "print(f\"\\nStep details:\")\n",
    "for i, step in enumerate(summary['steps']):\n",
    "    print(f\"  {i+1}. {step}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Bonus: Creating a Custom Agent from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_custom_agent(query: str, tools: list, llm, max_steps: int = 5):\n",
    "    \"\"\"\n",
    "    A simple custom agent implementation showing the ReAct loop.\n",
    "    \"\"\"\n",
    "    # Build tool descriptions\n",
    "    tool_descriptions = \"\\n\".join([\n",
    "        f\"- {t.name}: {t.description}\" for t in tools\n",
    "    ])\n",
    "    tool_names = [t.name for t in tools]\n",
    "    tool_map = {t.name: t for t in tools}\n",
    "    \n",
    "    # Initial prompt\n",
    "    conversation = f\"\"\"You are a helpful assistant with access to tools.\n",
    "\n",
    "Available tools:\n",
    "{tool_descriptions}\n",
    "\n",
    "To use a tool, respond with:\n",
    "TOOL: <tool_name>\n",
    "INPUT: <tool_input>\n",
    "\n",
    "When you have the final answer, respond with:\n",
    "FINAL: <your answer>\n",
    "\n",
    "Question: {query}\n",
    "\"\"\"\n",
    "    \n",
    "    print(f\"Query: {query}\\n\")\n",
    "    \n",
    "    for step in range(max_steps):\n",
    "        print(f\"--- Step {step + 1} ---\")\n",
    "        \n",
    "        # Get LLM response\n",
    "        response = llm.invoke(conversation).content\n",
    "        print(f\"LLM: {response[:200]}...\" if len(response) > 200 else f\"LLM: {response}\")\n",
    "        \n",
    "        # Check for final answer\n",
    "        if \"FINAL:\" in response:\n",
    "            final_answer = response.split(\"FINAL:\")[1].strip()\n",
    "            print(f\"\\nFinal Answer: {final_answer}\")\n",
    "            return final_answer\n",
    "        \n",
    "        # Check for tool use\n",
    "        if \"TOOL:\" in response and \"INPUT:\" in response:\n",
    "            tool_name = response.split(\"TOOL:\")[1].split(\"\\n\")[0].strip()\n",
    "            tool_input = response.split(\"INPUT:\")[1].split(\"\\n\")[0].strip()\n",
    "            \n",
    "            if tool_name in tool_map:\n",
    "                # Execute tool\n",
    "                tool_result = tool_map[tool_name].invoke(tool_input)\n",
    "                print(f\"Tool Result: {tool_result}\")\n",
    "                \n",
    "                # Add to conversation\n",
    "                conversation += f\"\\n\\nAssistant: {response}\\nObservation: {tool_result}\\n\\nContinue:\"\n",
    "            else:\n",
    "                conversation += f\"\\n\\nAssistant: {response}\\nObservation: Tool '{tool_name}' not found.\\n\\nContinue:\"\n",
    "        else:\n",
    "            conversation += f\"\\n\\nAssistant: {response}\\n\\nPlease use TOOL/INPUT format or provide FINAL answer:\"\n",
    "    \n",
    "    return \"Max steps reached without final answer\"\n",
    "\n",
    "\n",
    "# Test custom agent\n",
    "# run_custom_agent(\"What is 50 + 25?\", [calculator, weather_tool], llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Checkpoint\n",
    "\n",
    "Congratulations! You've completed Lab 2. You should now understand:\n",
    "\n",
    "- How to create custom tools with the `@tool` decorator\n",
    "- How to use Pydantic for structured tool inputs\n",
    "- How the ReAct pattern enables reasoning + acting\n",
    "- How to monitor agent execution with callbacks\n",
    "\n",
    "**Next:** Lab 3 - Advanced Agent Patterns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
