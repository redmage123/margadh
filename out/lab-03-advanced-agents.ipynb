{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3: Advanced Agent Patterns\n",
    "\n",
    "**Module 3 - Advanced Agent Development**\n",
    "\n",
    "| Duration | Difficulty | Framework | Exercises |\n",
    "|----------|------------|-----------|----------|\n",
    "| 120 min | Advanced | LangChain | 3 |\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Implement Chain-of-Thought reasoning\n",
    "- Build a Plan-and-Execute agent\n",
    "- Create a self-reflecting agent with critique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-api-key-here\"\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 1: Implement Chain-of-Thought Prompting\n",
    "\n",
    "Create a CoT prompt template that encourages step-by-step reasoning.\n",
    "\n",
    "**Your Task:** Design a prompt that guides the model through structured reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cot_prompt(question: str) -> str:\n",
    "    \"\"\"Create a Chain-of-Thought prompt.\"\"\"\n",
    "    # TODO: Design a prompt that encourages step-by-step reasoning\n",
    "    # Include explicit instructions to:\n",
    "    # 1. Identify what needs to be found\n",
    "    # 2. Break down the problem\n",
    "    # 3. Work through each part\n",
    "    # 4. Combine results for final answer\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "Question: {question}\n",
    "\n",
    "Let's solve this step by step:\n",
    "\n",
    "Step 1: [Identify what we need to find]\n",
    "Step 2: [Break down the problem]\n",
    "Step 3: [Work through each part]\n",
    "Step 4: [Combine results]\n",
    "\n",
    "Final Answer:\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def solve_with_cot(question: str) -> dict:\n",
    "    \"\"\"Solve a problem using Chain-of-Thought.\"\"\"\n",
    "    prompt = create_cot_prompt(question)\n",
    "    \n",
    "    # TODO: Call the LLM and parse the response\n",
    "    response = None  # Your code here\n",
    "    \n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"reasoning\": response,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test problems\n",
    "problems = [\n",
    "    \"A store has 45 apples. They sell 12 in the morning and receive a shipment of 30. How many apples do they have now?\",\n",
    "    \"If a train travels at 60 mph for 2 hours, then 80 mph for 1.5 hours, what's the total distance?\",\n",
    "    \"A rectangle has a perimeter of 24 cm. If the length is twice the width, what are the dimensions?\"\n",
    "]\n",
    "\n",
    "for problem in problems:\n",
    "    result = solve_with_cot(problem)\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Problem: {problem}\")\n",
    "    print(f\"\\nReasoning:\\n{result['reasoning']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 2: Build a Plan-and-Execute Agent\n",
    "\n",
    "Create an agent that first creates a plan, then executes each step.\n",
    "\n",
    "**Your Task:** Implement the planning and execution phases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlanAndExecuteAgent:\n",
    "    def __init__(self, llm):\n",
    "        self.llm = llm\n",
    "        self.plan = []\n",
    "        self.results = []\n",
    "    \n",
    "    def create_plan(self, task: str) -> list:\n",
    "        \"\"\"Create a step-by-step plan for the task.\"\"\"\n",
    "        planning_prompt = f\"\"\"\n",
    "You are a planning assistant. Create a detailed step-by-step plan for this task.\n",
    "Return the plan as a numbered list (1., 2., 3., etc.).\n",
    "Keep each step clear and actionable.\n",
    "\n",
    "Task: {task}\n",
    "\n",
    "Plan:\n",
    "1.\"\"\"\n",
    "        \n",
    "        # TODO: Generate plan and parse into list\n",
    "        response = None  # Your code here\n",
    "        \n",
    "        # Parse numbered list into steps\n",
    "        # Your parsing code here\n",
    "        self.plan = []\n",
    "        \n",
    "        return self.plan\n",
    "    \n",
    "    def execute_step(self, step: str, context: str) -> str:\n",
    "        \"\"\"Execute a single step of the plan.\"\"\"\n",
    "        execution_prompt = f\"\"\"\n",
    "Previous context: {context}\n",
    "\n",
    "Current step to execute: {step}\n",
    "\n",
    "Execute this step and provide a detailed result:\n",
    "\"\"\"\n",
    "        # TODO: Execute the step\n",
    "        response = None  # Your code here\n",
    "        return response\n",
    "    \n",
    "    def run(self, task: str) -> dict:\n",
    "        \"\"\"Run the full plan-and-execute cycle.\"\"\"\n",
    "        # Phase 1: Planning\n",
    "        print(\"Creating plan...\")\n",
    "        plan = self.create_plan(task)\n",
    "        print(f\"Plan created with {len(plan)} steps\")\n",
    "        \n",
    "        # Phase 2: Execution\n",
    "        context = \"\"\n",
    "        for i, step in enumerate(plan):\n",
    "            print(f\"\\nExecuting step {i+1}: {step[:50]}...\")\n",
    "            result = self.execute_step(step, context)\n",
    "            self.results.append({\"step\": step, \"result\": result})\n",
    "            context += f\"\\nStep {i+1} result: {result}\"\n",
    "        \n",
    "        return {\n",
    "            \"task\": task,\n",
    "            \"plan\": plan,\n",
    "            \"results\": self.results\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the agent\n",
    "# agent = PlanAndExecuteAgent(llm)\n",
    "# result = agent.run(\"Research and summarize the key differences between BERT and GPT models\")\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 3: Create a Self-Reflecting Agent\n",
    "\n",
    "Build an agent that critiques and improves its own output.\n",
    "\n",
    "**Your Task:** Implement the generate, critique, and improve cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReflectiveAgent:\n",
    "    def __init__(self, llm, max_iterations=3):\n",
    "        self.llm = llm\n",
    "        self.max_iterations = max_iterations\n",
    "    \n",
    "    def generate(self, task: str) -> str:\n",
    "        \"\"\"Generate initial response.\"\"\"\n",
    "        prompt = f\"Complete this task:\\n{task}\"\n",
    "        # TODO: Generate response\n",
    "        response = None  # Your code here\n",
    "        return response\n",
    "    \n",
    "    def critique(self, task: str, response: str) -> dict:\n",
    "        \"\"\"Critique the response and suggest improvements.\"\"\"\n",
    "        critique_prompt = f\"\"\"\n",
    "Task: {task}\n",
    "\n",
    "Response to critique:\n",
    "{response}\n",
    "\n",
    "Analyze this response and provide:\n",
    "1. Score (1-10)\n",
    "2. Strengths\n",
    "3. Weaknesses\n",
    "4. Specific improvements needed\n",
    "\n",
    "Format as JSON:\n",
    "{{\"score\": X, \"strengths\": [...], \"weaknesses\": [...], \"improvements\": [...]}}\n",
    "\"\"\"\n",
    "        # TODO: Generate critique and parse JSON\n",
    "        result = None  # Your code here\n",
    "        \n",
    "        try:\n",
    "            return json.loads(result)\n",
    "        except:\n",
    "            return {\"score\": 5, \"improvements\": [\"Could not parse critique\"]}\n",
    "    \n",
    "    def improve(self, task: str, response: str, critique: dict) -> str:\n",
    "        \"\"\"Improve response based on critique.\"\"\"\n",
    "        improve_prompt = f\"\"\"\n",
    "Task: {task}\n",
    "\n",
    "Previous response:\n",
    "{response}\n",
    "\n",
    "Critique feedback:\n",
    "- Weaknesses: {critique.get('weaknesses', [])}\n",
    "- Improvements needed: {critique.get('improvements', [])}\n",
    "\n",
    "Write an improved response addressing the feedback:\n",
    "\"\"\"\n",
    "        # TODO: Generate improved response\n",
    "        result = None  # Your code here\n",
    "        return result\n",
    "    \n",
    "    def run(self, task: str) -> dict:\n",
    "        \"\"\"Run the reflection loop.\"\"\"\n",
    "        response = self.generate(task)\n",
    "        history = [{\"iteration\": 0, \"response\": response}]\n",
    "        \n",
    "        for i in range(self.max_iterations):\n",
    "            critique = self.critique(task, response)\n",
    "            print(f\"Iteration {i+1} - Score: {critique.get('score', 'N/A')}\")\n",
    "            \n",
    "            if critique.get('score', 0) >= 8:\n",
    "                print(\"Quality threshold met!\")\n",
    "                break\n",
    "            \n",
    "            response = self.improve(task, response, critique)\n",
    "            history.append({\n",
    "                \"iteration\": i + 1,\n",
    "                \"critique\": critique,\n",
    "                \"response\": response\n",
    "            })\n",
    "        \n",
    "        return {\"final_response\": response, \"history\": history}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the reflective agent\n",
    "# agent = ReflectiveAgent(llm)\n",
    "# result = agent.run(\"Write a concise explanation of how neural networks learn\")\n",
    "# print(f\"\\nFinal Response:\\n{result['final_response']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Checkpoint\n",
    "\n",
    "Congratulations! You've completed Lab 3. You should now understand:\n",
    "\n",
    "- How Chain-of-Thought improves reasoning on complex problems\n",
    "- How Plan-and-Execute separates strategy from execution\n",
    "- How self-reflection enables iterative improvement\n",
    "\n",
    "**Next:** Lab 4 - RAG Pipeline Implementation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
