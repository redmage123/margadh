{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 6: LLM APIs - SOLUTIONS\n",
        "\n",
        "**Day 3 - From Deep Learning to LLMs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from openai import OpenAI\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"your-api-key-here\"\n",
        "client = OpenAI()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 1: Basic API Call - SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def simple_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# Test\n",
        "# print(simple_completion(\"What is machine learning in one sentence?\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 2: System Prompts - SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def completion_with_system(prompt, system_prompt, model=\"gpt-3.5-turbo\"):\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 3: Temperature and Tokens - SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def controlled_completion(prompt, temperature=0.7, max_tokens=100, model=\"gpt-3.5-turbo\"):\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=temperature,\n",
        "        max_tokens=max_tokens\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 4: Prompt Engineering - SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def zero_shot(task):\n",
        "    return simple_completion(task)\n",
        "\n",
        "def few_shot(task, examples):\n",
        "    prompt = \"\"\n",
        "    for inp, out in examples:\n",
        "        prompt += f\"Input: {inp}\\nOutput: {out}\\n\\n\"\n",
        "    prompt += f\"Input: {task}\\nOutput:\"\n",
        "    return simple_completion(prompt)\n",
        "\n",
        "def chain_of_thought(problem):\n",
        "    prompt = f\"{problem}\\n\\nLet's think step by step:\"\n",
        "    return simple_completion(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 5: Conversation History - SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SimpleChatbot:\n",
        "    def __init__(self, system_prompt=\"You are a helpful assistant.\"):\n",
        "        self.messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
        "    \n",
        "    def chat(self, user_message):\n",
        "        self.messages.append({\"role\": \"user\", \"content\": user_message})\n",
        "        \n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=self.messages\n",
        "        )\n",
        "        \n",
        "        assistant_message = response.choices[0].message.content\n",
        "        self.messages.append({\"role\": \"assistant\", \"content\": assistant_message})\n",
        "        \n",
        "        return assistant_message\n",
        "    \n",
        "    def get_history(self):\n",
        "        return self.messages\n",
        "    \n",
        "    def clear_history(self):\n",
        "        self.messages = [self.messages[0]]  # Keep system prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 6: Structured Output - SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_structured_data(text, schema_description):\n",
        "    system = f\"\"\"You are a data extraction assistant.\n",
        "Extract information from the text and return ONLY valid JSON.\n",
        "Expected format: {schema_description}\n",
        "Return ONLY the JSON, no other text.\"\"\"\n",
        "    \n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system},\n",
        "            {\"role\": \"user\", \"content\": text}\n",
        "        ]\n",
        "    )\n",
        "    \n",
        "    try:\n",
        "        return json.loads(response.choices[0].message.content)\n",
        "    except json.JSONDecodeError:\n",
        "        return None\n",
        "\n",
        "def summarize_with_structure(text):\n",
        "    schema = '''{\n",
        "        \"title\": \"brief title\",\n",
        "        \"summary\": \"2-3 sentence summary\",\n",
        "        \"key_points\": [\"point1\", \"point2\"],\n",
        "        \"sentiment\": \"positive/negative/neutral\"\n",
        "    }'''\n",
        "    return extract_structured_data(text, schema)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Checkpoint\n",
        "\n",
        "Lab 6 and entire course complete!\n",
        "\n",
        "### Course Summary:\n",
        "- **Lab 1:** Python for Data Science (NumPy, Pandas, Matplotlib)\n",
        "- **Lab 2:** ML Basics (Regression, Classification, Evaluation)\n",
        "- **Lab 3:** Neural Networks from Scratch\n",
        "- **Lab 4:** PyTorch Fundamentals\n",
        "- **Lab 5:** NLP Basics (Tokenization, Embeddings, Attention)\n",
        "- **Lab 6:** LLM APIs (OpenAI, Prompting, Chatbots)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
