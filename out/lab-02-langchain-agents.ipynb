{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: Building LangChain Agents\n",
    "\n",
    "**Module 2 - AI Agents and Framework Implementation**\n",
    "\n",
    "| Duration | Difficulty | Framework | Exercises |\n",
    "|----------|------------|-----------|----------|\n",
    "| 90 min | Intermediate | LangChain | 4 |\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Build custom tools for LangChain agents\n",
    "- Implement a ReAct agent from scratch\n",
    "- Create multi-tool agents\n",
    "- Add custom callbacks for monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "# !pip install langchain langchain-openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import tool, create_react_agent, AgentExecutor\n",
    "from langchain.tools import Tool, StructuredTool\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional\n",
    "\n",
    "# Set your API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-api-key-here\"  # Replace with your key\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 1: Create a Calculator Tool\n",
    "\n",
    "Build a simple calculator tool that can perform basic math operations.\n",
    "\n",
    "**Your Task:** Complete the calculator tool implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"\n",
    "    Evaluate a mathematical expression.\n",
    "    Use this tool for any math calculations.\n",
    "    Input should be a valid mathematical expression like '2 + 2' or '(5 * 3) - 10'.\n",
    "    \"\"\"\n",
    "    # TODO: Safely evaluate the mathematical expression\n",
    "    # Hint: Use eval() with caution, or implement a safer parser\n",
    "    \n",
    "    try:\n",
    "        # Your code here\n",
    "        result = None\n",
    "        return f\"Result: {result}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your calculator tool\n",
    "print(calculator.invoke(\"2 + 2\"))\n",
    "print(calculator.invoke(\"(10 * 5) / 2\"))\n",
    "print(calculator.invoke(\"2 ** 8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 2: Create a Weather Tool with Structured Input\n",
    "\n",
    "Build a weather lookup tool using Pydantic for structured input validation.\n",
    "\n",
    "**Your Task:** Complete the weather tool with proper input schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input schema\n",
    "class WeatherInput(BaseModel):\n",
    "    \"\"\"Input schema for weather lookup.\"\"\"\n",
    "    location: str = Field(description=\"The city name to get weather for\")\n",
    "    units: Optional[str] = Field(default=\"celsius\", description=\"Temperature units: celsius or fahrenheit\")\n",
    "\n",
    "\n",
    "def get_weather(location: str, units: str = \"celsius\") -> str:\n",
    "    \"\"\"\n",
    "    Get the current weather for a location.\n",
    "    This is a mock implementation - in production, call a real weather API.\n",
    "    \"\"\"\n",
    "    # TODO: Implement weather lookup (mock data for this exercise)\n",
    "    # Return a formatted string with weather information\n",
    "    \n",
    "    # Mock weather data\n",
    "    mock_weather = {\n",
    "        \"london\": {\"temp_c\": 15, \"condition\": \"Cloudy\"},\n",
    "        \"new york\": {\"temp_c\": 22, \"condition\": \"Sunny\"},\n",
    "        \"tokyo\": {\"temp_c\": 28, \"condition\": \"Humid\"},\n",
    "        \"paris\": {\"temp_c\": 18, \"condition\": \"Partly Cloudy\"},\n",
    "    }\n",
    "    \n",
    "    # Your code here\n",
    "    pass\n",
    "\n",
    "\n",
    "# Create the structured tool\n",
    "weather_tool = StructuredTool.from_function(\n",
    "    func=get_weather,\n",
    "    name=\"weather\",\n",
    "    description=\"Get current weather for a city. Provide location and optionally units (celsius/fahrenheit).\",\n",
    "    args_schema=WeatherInput\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your weather tool\n",
    "print(weather_tool.invoke({\"location\": \"London\"}))\n",
    "print(weather_tool.invoke({\"location\": \"Tokyo\", \"units\": \"fahrenheit\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 3: Build a Multi-Tool ReAct Agent\n",
    "\n",
    "Combine your tools into a ReAct agent that can reason and act.\n",
    "\n",
    "**Your Task:** Create and configure the agent executor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReAct prompt template\n",
    "REACT_PROMPT = \"\"\"Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "Thought: {agent_scratchpad}\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(REACT_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create the agent with your tools\n",
    "tools = None  # Your code here - list of tools\n",
    "\n",
    "# TODO: Create the ReAct agent\n",
    "agent = None  # Your code here\n",
    "\n",
    "# TODO: Create the agent executor\n",
    "agent_executor = None  # Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your agent with various queries\n",
    "queries = [\n",
    "    \"What is 25 * 4 + 100?\",\n",
    "    \"What's the weather like in London?\",\n",
    "    \"If it's 15 degrees in London and 28 degrees in Tokyo, what's the temperature difference?\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    print(\"-\" * 50)\n",
    "    # result = agent_executor.invoke({\"input\": query})\n",
    "    # print(f\"Answer: {result['output']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 4: Implement Custom Callbacks\n",
    "\n",
    "Create a custom callback handler to monitor agent execution.\n",
    "\n",
    "**Your Task:** Implement the callback methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentMonitorCallback(BaseCallbackHandler):\n",
    "    \"\"\"Custom callback handler for monitoring agent execution.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.steps = []\n",
    "        self.total_tokens = 0\n",
    "    \n",
    "    def on_llm_start(self, serialized, prompts, **kwargs):\n",
    "        \"\"\"Called when LLM starts processing.\"\"\"\n",
    "        # TODO: Log that LLM is starting\n",
    "        pass\n",
    "    \n",
    "    def on_llm_end(self, response, **kwargs):\n",
    "        \"\"\"Called when LLM finishes.\"\"\"\n",
    "        # TODO: Track token usage if available\n",
    "        pass\n",
    "    \n",
    "    def on_tool_start(self, serialized, input_str, **kwargs):\n",
    "        \"\"\"Called when a tool starts executing.\"\"\"\n",
    "        # TODO: Log tool name and input\n",
    "        tool_name = serialized.get(\"name\", \"unknown\")\n",
    "        pass\n",
    "    \n",
    "    def on_tool_end(self, output, **kwargs):\n",
    "        \"\"\"Called when a tool finishes.\"\"\"\n",
    "        # TODO: Log tool output\n",
    "        pass\n",
    "    \n",
    "    def on_agent_action(self, action, **kwargs):\n",
    "        \"\"\"Called when agent decides on an action.\"\"\"\n",
    "        # TODO: Record the action\n",
    "        self.steps.append({\n",
    "            \"type\": \"action\",\n",
    "            \"tool\": action.tool,\n",
    "            \"input\": action.tool_input\n",
    "        })\n",
    "    \n",
    "    def on_agent_finish(self, finish, **kwargs):\n",
    "        \"\"\"Called when agent completes.\"\"\"\n",
    "        # TODO: Log final output\n",
    "        pass\n",
    "    \n",
    "    def get_summary(self):\n",
    "        \"\"\"Return execution summary.\"\"\"\n",
    "        return {\n",
    "            \"total_steps\": len(self.steps),\n",
    "            \"steps\": self.steps,\n",
    "            \"tokens_used\": self.total_tokens\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with callbacks\n",
    "callback = AgentMonitorCallback()\n",
    "\n",
    "# Recreate executor with callbacks\n",
    "# agent_executor_with_callbacks = AgentExecutor(\n",
    "#     agent=agent,\n",
    "#     tools=tools,\n",
    "#     verbose=True,\n",
    "#     callbacks=[callback]\n",
    "# )\n",
    "\n",
    "# Run a query\n",
    "# result = agent_executor_with_callbacks.invoke({\"input\": \"What is 15 * 8 and what's the weather in Paris?\"})\n",
    "\n",
    "# Get summary\n",
    "# print(\"\\nExecution Summary:\")\n",
    "# print(callback.get_summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Checkpoint\n",
    "\n",
    "Congratulations! You've completed Lab 2. You should now understand:\n",
    "\n",
    "- How to create custom tools with the `@tool` decorator\n",
    "- How to use Pydantic for structured tool inputs\n",
    "- How the ReAct pattern enables reasoning + acting\n",
    "- How to monitor agent execution with callbacks\n",
    "\n",
    "**Next:** Lab 3 - Advanced Agent Patterns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
