{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4: RAG Pipeline Implementation\n",
    "\n",
    "**Module 4 - Retrieval-Augmented Generation**\n",
    "\n",
    "| Duration | Difficulty | Framework | Exercises |\n",
    "|----------|------------|-----------|----------|\n",
    "| 120 min | Advanced | LangChain + FAISS | 4 |\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Implement document loading and text chunking strategies\n",
    "- Generate and store embeddings using OpenAI and FAISS\n",
    "- Build semantic search with similarity scoring\n",
    "- Create a complete RAG pipeline with context injection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain langchain-openai faiss-cpu tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.schema import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-api-key-here\"\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample documents\n",
    "documents = [\n",
    "    \"\"\"Machine Learning is a subset of artificial intelligence that enables\n",
    "    systems to learn and improve from experience without being explicitly\n",
    "    programmed. It focuses on developing computer programs that can access\n",
    "    data and use it to learn for themselves.\n",
    "\n",
    "    The process begins with observations or data, such as examples, direct\n",
    "    experience, or instruction. It looks for patterns in data and makes\n",
    "    better decisions in the future based on the examples provided.\n",
    "\n",
    "    There are three main types of machine learning: supervised learning,\n",
    "    unsupervised learning, and reinforcement learning.\"\"\",\n",
    "\n",
    "    \"\"\"Deep Learning is part of a broader family of machine learning methods\n",
    "    based on artificial neural networks. Learning can be supervised,\n",
    "    semi-supervised or unsupervised.\n",
    "\n",
    "    Deep learning architectures such as deep neural networks, recurrent\n",
    "    neural networks, convolutional neural networks and transformers have\n",
    "    been applied to fields including computer vision, speech recognition,\n",
    "    natural language processing, and machine translation.\n",
    "\n",
    "    Neural networks are inspired by biological neural networks, although\n",
    "    they are not identical.\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 1: Document Chunking\n",
    "\n",
    "Implement different text chunking strategies and compare their effectiveness.\n",
    "\n",
    "**Your Task:** Complete the chunking function and analyze different strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chunks(texts: list, chunk_size: int, chunk_overlap: int) -> list:\n",
    "    \"\"\"Create chunks from a list of texts.\"\"\"\n",
    "    # TODO: Initialize RecursiveCharacterTextSplitter\n",
    "    splitter = None  # Your code here\n",
    "    \n",
    "    # TODO: Split all documents and return chunks as Document objects\n",
    "    all_chunks = []\n",
    "    # Your code here\n",
    "    \n",
    "    return all_chunks\n",
    "\n",
    "\n",
    "def analyze_chunking_strategy(texts: list):\n",
    "    \"\"\"Compare different chunking strategies.\"\"\"\n",
    "    strategies = [\n",
    "        {\"chunk_size\": 100, \"chunk_overlap\": 20},\n",
    "        {\"chunk_size\": 200, \"chunk_overlap\": 40},\n",
    "        {\"chunk_size\": 500, \"chunk_overlap\": 50},\n",
    "    ]\n",
    "    \n",
    "    for strategy in strategies:\n",
    "        chunks = create_chunks(texts, **strategy)\n",
    "        print(f\"\\n--- Strategy: {strategy} ---\")\n",
    "        print(f\"Number of chunks: {len(chunks)}\")\n",
    "        if chunks:\n",
    "            avg_len = sum(len(c.page_content) for c in chunks) / len(chunks)\n",
    "            print(f\"Average chunk length: {avg_len:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run analysis\n",
    "# analyze_chunking_strategy(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 2: Embedding Generation and Vector Store\n",
    "\n",
    "Generate embeddings and create a FAISS vector store.\n",
    "\n",
    "**Your Task:** Create a vector store and analyze embedding properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_store(documents: list) -> FAISS:\n",
    "    \"\"\"Create a FAISS vector store from documents.\"\"\"\n",
    "    # TODO: Create chunks from documents\n",
    "    chunks = None  # Your code here\n",
    "    \n",
    "    # TODO: Create FAISS vector store with embeddings\n",
    "    vector_store = None  # Your code here\n",
    "    \n",
    "    return vector_store\n",
    "\n",
    "\n",
    "def compare_similarities(texts: list):\n",
    "    \"\"\"Compare semantic similarities between texts.\"\"\"\n",
    "    # TODO: Generate embeddings for all texts\n",
    "    text_embeddings = None  # Your code here\n",
    "    \n",
    "    # TODO: Calculate and display cosine similarities\n",
    "    print(\"\\nSimilarity Matrix:\")\n",
    "    # Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "test_texts = [\n",
    "    \"Machine learning uses data to make predictions\",\n",
    "    \"Deep learning is based on neural networks\",\n",
    "    \"The weather today is sunny and warm\",\n",
    "    \"AI systems can learn from experience\"\n",
    "]\n",
    "# compare_similarities(test_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 3: Semantic Search\n",
    "\n",
    "Implement semantic search with relevance scoring.\n",
    "\n",
    "**Your Task:** Build search functions with different retrieval methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(vector_store, query: str, k: int = 3) -> list:\n",
    "    \"\"\"Perform semantic search and return results with scores.\"\"\"\n",
    "    # TODO: Perform similarity search with scores\n",
    "    results = None  # Your code here\n",
    "    \n",
    "    formatted_results = []\n",
    "    # TODO: Format results with content, metadata, and similarity scores\n",
    "    \n",
    "    return formatted_results\n",
    "\n",
    "\n",
    "def compare_search_methods(vector_store, query: str):\n",
    "    \"\"\"Compare different search methods.\"\"\"\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # TODO: Implement basic search, search with scores, and MMR search\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 4: Complete RAG Pipeline\n",
    "\n",
    "Build a complete RAG pipeline that retrieves context and generates responses.\n",
    "\n",
    "**Your Task:** Implement the RAGPipeline class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGPipeline:\n",
    "    def __init__(self, vector_store, llm, k: int = 3):\n",
    "        self.vector_store = vector_store\n",
    "        self.llm = llm\n",
    "        self.k = k\n",
    "        \n",
    "        # TODO: Define the RAG prompt template\n",
    "        self.prompt = None  # Your code here\n",
    "    \n",
    "    def retrieve(self, query: str) -> str:\n",
    "        \"\"\"Retrieve relevant documents and format as context.\"\"\"\n",
    "        # TODO: Retrieve documents and format them\n",
    "        pass\n",
    "    \n",
    "    def generate(self, question: str, context: str) -> str:\n",
    "        \"\"\"Generate response using retrieved context.\"\"\"\n",
    "        # TODO: Generate response\n",
    "        pass\n",
    "    \n",
    "    def query(self, question: str) -> dict:\n",
    "        \"\"\"Run the full RAG pipeline.\"\"\"\n",
    "        # TODO: Implement retrieve and generate\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test RAG pipeline\n",
    "# vector_store = create_vector_store(documents)\n",
    "# rag = RAGPipeline(vector_store, llm)\n",
    "# result = rag.query(\"What are the types of machine learning?\")\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Checkpoint\n",
    "\n",
    "You've completed Lab 4! Key concepts:\n",
    "\n",
    "- Document chunking affects retrieval quality\n",
    "- Embeddings capture semantic meaning\n",
    "- RAG combines retrieval with generation for grounded responses\n",
    "\n",
    "**Next:** Lab 5 - LoRA Fine-tuning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
