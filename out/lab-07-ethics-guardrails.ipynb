{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 7: Ethical AI & Guardrails\n",
    "\n",
    "**Module 7 - Responsible AI Implementation**\n",
    "\n",
    "| Duration | Difficulty | Framework | Exercises |\n",
    "|----------|------------|-----------|----------|\n",
    "| 90 min | Intermediate | OpenAI + Custom | 4 |\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Implement content moderation using OpenAI's Moderation API\n",
    "- Build custom input/output guardrails\n",
    "- Create bias detection mechanisms\n",
    "- Design audit logging and compliance systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from datetime import datetime\n",
    "from openai import OpenAI\n",
    "from typing import Optional\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-api-key-here\"\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 1: OpenAI Moderation API\n",
    "\n",
    "Use OpenAI's Moderation API to detect harmful content.\n",
    "\n",
    "**Your Task:** Implement content moderation checking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_moderation(text: str) -> dict:\n",
    "    \"\"\"Check text against OpenAI's moderation endpoint.\"\"\"\n",
    "    # TODO: Call client.moderations.create(input=text)\n",
    "    # TODO: Extract flagged status and category scores\n",
    "    pass\n",
    "\n",
    "def analyze_moderation_result(result: dict) -> str:\n",
    "    \"\"\"Analyze and format moderation results.\"\"\"\n",
    "    # TODO: Format which categories were flagged\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "test_texts = [\n",
    "    \"How do I write a Python function?\",\n",
    "    \"What's the weather today?\",\n",
    "]\n",
    "\n",
    "# for text in test_texts:\n",
    "#     result = check_moderation(text)\n",
    "#     print(f\"Text: {text[:40]}... Flagged: {result['flagged']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 2: Custom Input Guardrails\n",
    "\n",
    "Build comprehensive input validation.\n",
    "\n",
    "**Your Task:** Implement PII detection and injection prevention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputGuardrails:\n",
    "    def __init__(self):\n",
    "        self.pii_patterns = {\n",
    "            \"email\": r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b',\n",
    "            \"phone\": r'\\b\\d{3}[-.]?\\d{3}[-.]?\\d{4}\\b',\n",
    "            \"ssn\": r'\\b\\d{3}-\\d{2}-\\d{4}\\b',\n",
    "        }\n",
    "        self.injection_patterns = [\n",
    "            r'ignore\\s+(previous|all)\\s+instructions',\n",
    "            r'you\\s+are\\s+now\\s+',\n",
    "            r'system\\s*:\\s*',\n",
    "        ]\n",
    "    \n",
    "    def detect_pii(self, text: str) -> tuple:\n",
    "        \"\"\"Detect PII in text.\"\"\"\n",
    "        # TODO: Check each PII pattern and return findings\n",
    "        pass\n",
    "    \n",
    "    def detect_injection(self, text: str) -> tuple:\n",
    "        \"\"\"Detect prompt injection attempts.\"\"\"\n",
    "        # TODO: Check injection patterns\n",
    "        pass\n",
    "    \n",
    "    def validate(self, text: str) -> dict:\n",
    "        \"\"\"Run all validation checks.\"\"\"\n",
    "        # TODO: Combine all checks and return results\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 3: Output Guardrails\n",
    "\n",
    "Validate and sanitize LLM outputs.\n",
    "\n",
    "**Your Task:** Implement output validation and PII redaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutputGuardrails:\n",
    "    def __init__(self):\n",
    "        self.hallucination_markers = [\n",
    "            r\"as an ai,? i (don't|cannot) know\",\n",
    "            r\"i('m| am) not sure\",\n",
    "        ]\n",
    "    \n",
    "    def detect_hallucination_markers(self, text: str) -> tuple:\n",
    "        \"\"\"Detect potential hallucination indicators.\"\"\"\n",
    "        # TODO: Check for hallucination markers\n",
    "        pass\n",
    "    \n",
    "    def redact_pii(self, text: str) -> str:\n",
    "        \"\"\"Redact PII from output.\"\"\"\n",
    "        # TODO: Replace PII patterns with [REDACTED]\n",
    "        pass\n",
    "    \n",
    "    def validate(self, text: str) -> dict:\n",
    "        \"\"\"Validate output and return sanitized version.\"\"\"\n",
    "        # TODO: Run checks and return results with sanitized text\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 4: Audit Logging System\n",
    "\n",
    "Create comprehensive audit logging for compliance.\n",
    "\n",
    "**Your Task:** Implement structured logging with metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import uuid\n",
    "from dataclasses import dataclass, asdict\n",
    "\n",
    "@dataclass\n",
    "class AuditEntry:\n",
    "    request_id: str\n",
    "    timestamp: str\n",
    "    user_id: str\n",
    "    input_hash: str\n",
    "    input_passed: bool\n",
    "    output_hash: str\n",
    "    output_passed: bool\n",
    "    model_name: str\n",
    "    latency_ms: float\n",
    "\n",
    "class AuditLogger:\n",
    "    def __init__(self, log_file: str = \"audit_log.jsonl\"):\n",
    "        self.log_file = log_file\n",
    "        self.entries = []\n",
    "    \n",
    "    def hash_content(self, text: str) -> str:\n",
    "        \"\"\"Create hash of content.\"\"\"\n",
    "        # TODO: Return SHA256 hash prefix\n",
    "        pass\n",
    "    \n",
    "    def create_entry(self, user_id: str, input_text: str, input_validation: dict,\n",
    "                     output_text: str, output_validation: dict, model_name: str, latency_ms: float):\n",
    "        \"\"\"Create and store an audit entry.\"\"\"\n",
    "        # TODO: Create AuditEntry and append to entries\n",
    "        pass\n",
    "    \n",
    "    def get_statistics(self) -> dict:\n",
    "        \"\"\"Calculate statistics from logged entries.\"\"\"\n",
    "        # TODO: Calculate failure rates, totals, etc.\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Checkpoint\n",
    "\n",
    "You've completed Lab 7! Key concepts:\n",
    "\n",
    "- Moderation API catches harmful content automatically\n",
    "- Input guardrails prevent PII leakage and injection attacks\n",
    "- Output guardrails ensure safe, sanitized responses\n",
    "- Audit logging enables compliance and debugging\n",
    "\n",
    "**Congratulations!** You've completed all 7 labs in the Mastering LLMs course."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
